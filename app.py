import streamlit as st
import requests
from bs4 import BeautifulSoup
import pandas as pd

st.set_page_config(page_title="ã¿ã‚“ã‹ã¶éŠ˜æŸ„ãƒã‚§ãƒƒã‚«ãƒ¼", layout="wide")

class MinkabuScraper:
    def __init__(self, code):
        self.code = code
        self.headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        self.base_url = f"https://minkabu.jp/stock/{code}"
        self.yutai_url = f"https://minkabu.jp/stock/{code}/yutai"

    def get_soup(self, url):
        try:
            res = requests.get(url, headers=self.headers, timeout=10)
            res.encoding = "utf-8"
            return BeautifulSoup(res.text, "html.parser")
        except:
            return None

    def scrape_data(self):
        soup = self.get_soup(self.base_url)
        if not soup or "æŒ‡å®šã•ã‚ŒãŸãƒšãƒ¼ã‚¸ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ" in soup.text:
            return None

        # éŠ˜æŸ„å
        name_tag = soup.find("p", class_="md_stockBoard_stockName")
        name = name_tag.text.strip() if name_tag else "ä¸æ˜"

        # æ ªä¾¡
        price_tag = soup.find("div", class_="stock_price")
        price = price_tag.text.strip() if price_tag else "å–å¾—ä¸å¯"

        # åˆ©å›ã‚Šãƒ»é…å½“ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢ï¼‰
        dividend_yield = "ï¼"
        dividend_value = "ï¼"
        tables = soup.find_all("table", class_="md_table")
        for table in tables:
            rows = table.find_all("tr")
            for row in rows:
                if "é…å½“åˆ©å›ã‚Š" in row.text:
                    dividend_yield = row.find("td").text.strip()
                if "1æ ªé…å½“" in row.text:
                    dividend_value = row.find("td").text.strip()

        # å„ªå¾…æƒ…å ±
        yutai_soup = self.get_soup(self.yutai_url)
        yutai_content = "ãªã—"
        yutai_month = "ï¼"
        
        if yutai_soup:
            y_month = yutai_soup.find("div", class_="ly_content_main")
            if y_month:
                # ç°¡æ˜“çš„ã«æœ€åˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ã®å†…å®¹ã‚’å–å¾—
                y_table = yutai_soup.find("table", class_="md_table")
                if y_table:
                    yutai_content = y_table.get_text(separator=" ").strip()[:100] + "..."

        return {
            "éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰": self.code,
            "éŠ˜æŸ„å": name,
            "æ ªä¾¡": price,
            "é…å½“åˆ©å›ã‚Š": dividend_yield,
            "1æ ªé…å½“": dividend_value,
            "å„ªå¾…å†…å®¹": yutai_content
        }

# UIéƒ¨åˆ†
st.title("ğŸ“ˆ ã¿ã‚“ã‹ã¶æƒ…å ±ãƒã‚§ãƒƒã‚«ãƒ¼")
code_input = st.sidebar.text_input("éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ã‚’å…¥åŠ›")

if code_input:
    scraper = MinkabuScraper(code_input)
    data = scraper.scrape_data()
    if data:
        st.dataframe(pd.DataFrame([data]).T, use_container_width=True)
        st.link_button("ã¿ã‚“ã‹ã¶ã§è©³ç´°ã‚’è¦‹ã‚‹", f"https://minkabu.jp/stock/{code_input}")
    else:
        st.error("ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

st.caption("ã€å…è²¬äº‹é …ã€‘æœ¬ãƒ„ãƒ¼ãƒ«ã¯å­¦ç¿’ç”¨ã§ã‚ã‚Šã€å–å¾—ãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã—ã¾ã›ã‚“ã€‚ã¿ã‚“ã‹ã¶ã®åˆ©ç”¨è¦ç´„ã‚’éµå®ˆã—ã¦ãã ã•ã„ã€‚")
